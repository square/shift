--- pt-online-schema-change
+++ pt-online-schema-change
@@ -28,6 +28,7 @@ BEGIN {
       TableNibbler
       TableParser
       Progress
+      State
       Retry
       Cxn
       MasterSlave
@@ -3700,6 +3701,11 @@ sub set_callback {
    $self->{callback} = $callback;
 }
 
+sub set_jobsize {
+   my ( $self, $jobsize ) = @_;
+   $self->{jobsize} = $jobsize;
+}
+
 sub start {
    my ( $self, $start ) = @_;
    $self->{start} = $self->{last_reported} = $start || time();
@@ -3780,6 +3786,93 @@ sub _d {
 # End Progress package
 # ###########################################################################
 
+# ###########################################################################
+# State package
+# Written at Square
+# ###########################################################################
+{
+package State;
+
+use strict;
+use warnings FATAL => 'all';
+use YAML::Syck;
+use English qw(-no_match_vars);
+use constant PTDEBUG => $ENV{PTDEBUG} || 0;
+
+sub new {
+   my ( $class, %args ) = @_;
+   foreach my $arg (qw(state_file)) {
+      die "I need a $arg argument" unless defined $args{$arg};
+   }
+
+   my $self;
+   $self = {
+      db         => $args{db},
+      dsn        => $args{dsn},
+      options    => $args{options},
+      orig_tbl   => $args{orig_tbl},
+      state_file => $args{state_file},
+      %args,
+   };
+   return bless $self, $class;
+}
+
+sub save {
+   my ( $self, %args) = @_;
+   my @required_args = qw(step);
+   foreach my $arg ( @required_args ) {
+      die "I need a $arg argument" unless $args{$arg};
+   }
+
+   my %state;
+   $state{'step'} = $args{step};
+   $state{'row'} = $args{row};
+   $state{'mig_tbl'} = $args{mig_tbl};
+   $state{'old_tbl'} = $args{old_tbl};
+   $state{'tbl_progress'} = $args{tbl_progress};
+   $state{'options'} = $self->{options};
+   $state{'orig_tbl'} = $self->{orig_tbl};
+   $state{'db'} = $self->{db};
+   $state{'dsn'} = $self->{dsn};
+
+   my $filename = $self->{state_file};
+   open( my $fh, '>', $filename ) or die "Could not open file '$filename' $!";
+   print $fh YAML::Syck::Dump( \%state );
+   close $fh;
+}
+
+sub load {
+   my ( $self, %args) = @_;
+   my $filename = $self->{state_file};
+
+   my $file_content = LoadFile($filename);
+   my $step = $file_content->{step};
+   my $row = $file_content->{row};
+   my $mig_tbl = $file_content->{mig_tbl};
+   my $old_tbl = $file_content->{old_tbl};
+   my $tbl_progress = $file_content->{tbl_progress};
+   my $orig_tbl = $file_content->{orig_tbl};
+   my $options = $file_content->{options};
+   my $db = $file_content->{db};
+   my $dsn = $file_content->{dsn};
+
+   return ($step, $row, $mig_tbl, $old_tbl, $tbl_progress, $options, $orig_tbl, $db, $dsn);
+}
+
+sub _d {
+   my ($package, undef, $line) = caller 0;
+   @_ = map { (my $temp = $_) =~ s/\n/\n# /g; $temp; }
+        map { defined $_ ? $_ : 'undef' }
+        @_;
+   print STDERR "# $package:$line $PID ", join(' ', @_), "\n";
+}
+
+1;
+}
+# ###########################################################################
+# End State package
+# ###########################################################################
+
 # ###########################################################################
 # Retry package
 # This package is a copy without comments from the original.  The original
@@ -5666,7 +5759,7 @@ sub new {
 }
 
 sub next {
-   my ($self) = @_;
+   my ($self, $o) = @_;
 
    if ( !$self->{oktonibble} ) {
       PTDEBUG && _d('Not ok to nibble');
@@ -5681,7 +5774,7 @@ sub next {
 
    if ($self->{nibbleno} == 0) {
       $self->_prepare_sths();
-      $self->_get_bounds();
+      $self->_get_bounds($o);
       if ( my $callback = $self->{callbacks}->{init} ) {
          $self->{oktonibble} = $callback->(%callback_args);
          PTDEBUG && _d('init callback returned', $self->{oktonibble});
@@ -5802,7 +5895,7 @@ sub set_boundary {
    die "I need a boundary parameter"
       unless $boundary;
    die "Invalid boundary: $boundary"
-      unless $boundary =~ m/^(?:lower|upper|next_lower|last_upper)$/;
+      unless $boundary =~ m/^(?:lower|upper|next_lower|last_upper|first_lower)$/;
    die "I need a values arrayref parameter"
       unless $values && ref $values eq 'ARRAY';
    $self->{$boundary} = $values;
@@ -6027,7 +6120,7 @@ sub _prepare_sths {
 }
 
 sub _get_bounds { 
-   my ($self) = @_;
+   my ($self, $o) = @_;
 
    if ( $self->{one_nibble} ) {
       if ( $self->{resume} ) {
@@ -6039,6 +6132,13 @@ sub _get_bounds {
    my $dbh = $self->{Cxn}->dbh();
 
    $self->{first_lower} = $dbh->selectrow_arrayref($self->{first_lb_sql});
+
+   # Override NibbleIterator->{first_lower} to be the row from a saved-state file.
+   # This means that the row copies will start at the primary key value saved in the file.
+   if ( defined $self->{loaded_step} && $self->{loaded_step} eq 'copy' ) {
+      $self->{first_lower} = $self->{loaded_row};
+   }
+
    PTDEBUG && _d('First lower boundary:', Dumper($self->{first_lower}));  
 
    if ( my $nibble = $self->{resume} ) {
@@ -8333,22 +8433,65 @@ sub main {
    # on the command line via the DSN.
    my ($db, $tbl);
    my $dsn = shift @ARGV;
-   if ( !$dsn ) {
-      $o->save_error('A DSN must be specified');
-   }
-   else {
+   if ( $dsn ) {
       # Parse DSN string and convert it to a DSN data struct.
       $dsn = $dp->parse($dsn, $dp->parse_options($o));
       $db  = $dsn->{D};
-      $tbl = $dsn->{t};  
+      $tbl = $dsn->{t};
+   }
+   elsif ( !$o->get('load-state') ) {
+      $o->save_error('A DSN must be specified');
+   }
+
+   # ########################################################################
+   # Setup the state.
+   # ########################################################################
+   my $save_state = $o->get('save-state');
+   my $load_state = $o->get('load-state');
+
+   my ($loaded_state, $loaded_step, $loaded_row, $loaded_db, $loaded_dsn, $loaded_options);
+   my ($loaded_orig_table, $loaded_mig_tbl, $loaded_old_tbl, $loaded_tbl_progress);
+   if ( $load_state ) {
+      $loaded_state = new State(state_file => $load_state);
+      ($loaded_step, $loaded_row, $loaded_mig_tbl, $loaded_old_tbl, $loaded_tbl_progress, $loaded_options,
+         $loaded_orig_table, $loaded_db, $loaded_dsn) = $loaded_state->load();
+      $dsn = $loaded_dsn;
+      $db = $loaded_db;
+      $tbl = $loaded_orig_table;
+   }
+
+   if ( $loaded_options ){
+      # Capture any options you want from the current run.
+      my $current_exit_at = $o->get('exit-at');
+
+      # Load up all of the options from the previous run, and override the options
+      # you want from the current run.
+      $o = bless($loaded_options, 'OptionParser');
+      $o->{'opts'}{'exit-at'}{'value'} = $current_exit_at;
+   }
+
+   my $current_state;
+   if ( $save_state ) {
+      $current_state = new State(
+         db         => $db,
+         dsn        => $dsn,
+         options    => $o,
+         orig_tbl   => $tbl,
+         state_file => $save_state,
+      );
    }
 
+   # ########################################################################
+   # Continue getting configuration information.
+   # ########################################################################
    my $alter_fk_method = $o->get('alter-foreign-keys-method') || '';
    if ( $alter_fk_method eq 'drop_swap' ) {
       $o->set('swap-tables',    0);
       $o->set('drop-old-table', 0);
    }
 
+   my $update_tablesize_interval = $o->get('update-tablesize-interval');
+
    # Explicit --chunk-size disable auto chunk sizing.
    $o->set('chunk-time', 0) if $o->got('chunk-size');
    if (!$o->get('swap-tables') && !$o->get('drop-triggers')) {
@@ -8889,6 +9032,7 @@ sub main {
    };
 
    check_orig_table(
+      loaded_step  => $loaded_step,
       orig_tbl     => $orig_tbl,
       Cxn          => $cxn,
       OptionParser => $o,
@@ -9123,12 +9267,26 @@ sub main {
       );
    }
 
+   if ( defined $loaded_step && $loaded_step eq 'rename' ) {
+      # If the tables have already been renamed, we can skip most steps
+      # since all we need to do is cleanup.
+      goto SAVED_RENAME;
+   }
+
    # #####################################################################
    # Step 1: Create the new table.
    # #####################################################################
 
-   my $new_table_name   = $o->get('new-table-name');
-   my $new_table_prefix = $o->got('new-table-name') ? undef : '_';
+   my $new_table_name;
+   my $new_table_prefix;
+   if ( $loaded_mig_tbl ) {
+      $new_table_name = $loaded_mig_tbl;
+      $new_table_prefix = '';
+   }
+   else {
+      $new_table_name = $o->get('new-table-name');
+      $new_table_prefix = $o->got('new-table-name') ? undef : '_';
+   }
 
    # --plugin hook
   if ( $plugin && $plugin->can('before_create_new_table') ) {
@@ -9141,6 +9299,7 @@ sub main {
    my $new_tbl;
    eval {
       $new_tbl = create_new_table(
+         loaded_step      => $loaded_step,
          new_table_name   => $new_table_name,
          new_table_prefix => $new_table_prefix,
          orig_tbl         => $orig_tbl,
@@ -9174,6 +9333,11 @@ sub main {
              . "the tool was interrupted.  To drop the new table, "
              . "execute:\n$sql\n";
       }
+      elsif ( defined $o->get('exit-at') && grep { $_ eq $o->get('exit-at') } qw(create triggers copy rename) ) {
+         print "Not dropping the new table $new_tbl->{name} because "
+             . "--exit-at was specified.  To drop the new table, "
+             . "execute:\n$sql\n";
+      }
       elsif ( $orig_tbl->{copied} && !$orig_tbl->{swapped} ) {
          print "Not dropping the new table $new_tbl->{name} because "
              . "--swap-tables failed.  To drop the new table, "
@@ -9262,7 +9426,10 @@ sub main {
       );
    }
 
-   if ( my $alter = $o->get('alter') ) {
+   # Don't alter the temp table if you're starting from a saved state (it
+   # has already been altered).
+   if ( (my $alter = $o->get('alter')) &&
+         (!defined $loaded_step || (defined $loaded_step && !grep { $_ eq $loaded_step } qw(create triggers copy rename)))) {
       print "Altering new table...\n";
       my $sql = "ALTER TABLE $new_tbl->{name} $alter";
       print $sql, "\n" if $o->get('print');
@@ -9381,6 +9548,16 @@ sub main {
       );
    }
 
+   if ( $current_state) {
+      $current_state->save(
+         step    => 'create',
+         mig_tbl => $new_tbl->{tbl}
+      );
+   }
+   if ( defined $o->get('exit-at') && $o->get('exit-at') eq 'create' ) {
+      return 0;
+   }
+
    # ########################################################################
    # Step 3: Create the triggers to capture changes on the original table and
    # apply them to the new table.
@@ -9413,6 +9590,11 @@ sub main {
          . "specified.  To drop the triggers, execute:\n"
          . join("\n", @drop_trigger_sqls) . "\n";
       }
+      elsif ( defined $o->get('exit-at') && grep { $_ eq $o->get('exit-at') } qw(triggers copy rename) ) {
+         print "Not dropping triggers because --exit-at was "
+         . "specified.  To drop the triggers, execute:\n"
+         . join("\n", @drop_trigger_sqls) . "\n";
+      }
       else {
          drop_triggers(
             tbl          => $orig_tbl,
@@ -9433,6 +9615,7 @@ sub main {
 
    my @trigger_names = eval {
       create_triggers(
+         loaded_step  => $loaded_step,
          orig_tbl     => $orig_tbl,
          new_tbl      => $new_tbl,
          del_tbl      => $del_tbl,
@@ -9454,6 +9637,16 @@ sub main {
       $plugin->after_create_triggers();
    }
 
+   if ( $current_state) {
+      $current_state->save(
+         step    => 'triggers',
+         mig_tbl => $new_tbl->{tbl}
+      );
+   }
+   if ( defined $o->get('exit-at') && $o->get('exit-at') eq 'triggers' ) {
+      return 0;
+   }
+
    # #####################################################################
    # Step 4: Copy rows.
    # #####################################################################
@@ -9462,11 +9655,13 @@ sub main {
    # to do all the copy work.  The callbacks do not need to eval their work
    # because the higher call to $nibble_iter->next() is eval'ed which will
    # catch any errors in the callbacks.
-   my $total_rows = 0;
-   my $total_time = 0;
-   my $avg_rate   = 0;  # rows/second
-   my $limit      = $o->get('chunk-size-limit');  # brevity
-   my $chunk_time = $o->get('chunk-time');        # brevity
+   my $total_rows         = 0;
+   my $total_time         = 0;
+   my $last_prog_upd_time = 0;
+   my $avg_rate           = 0;  # rows/second
+   my $limit              = $o->get('chunk-size-limit');  # brevity
+   my $chunk_time         = $o->get('chunk-time');        # brevity
+   my $copy_start         = time;
 
    my $callbacks = {
       init => sub {
@@ -9652,16 +9847,12 @@ sub main {
 
          return unless $o->get('execute');
 
-         # Update rate, chunk size, and progress if the nibble actually
-         # selected some rows.
+         # Update rate and chunk size if the nibble actually selected
+         # some rows.
          my $cnt = $tbl->{row_cnt};
          if ( ($cnt || 0) > 0 ) {
-            # Update the rate of rows per second for the entire server.
-            # This is used for the initial chunk size of the next table.
+            # Add the number of rows copied to the total rows counter.
             $total_rows += $cnt;
-            $total_time += $tbl->{nibble_time};
-            $avg_rate    = int($total_rows / $total_time);
-            PTDEBUG && _d('Average copy rate (rows/s):', $avg_rate);
 
             # Adjust chunk size.  This affects the next chunk.
             if ( $chunk_time ) {
@@ -9692,10 +9883,62 @@ sub main {
                # Update chunk-size based on the rate of rows/s.
                $nibble_iter->set_chunk_size($tbl->{chunk_size});
             }
+         } else {
+            # Add the chunk size to the total rows counter. This path is
+            # reached when all of the rows in a chunk already exist in
+            # the new table. We still want to keep track of this count
+            # though so we can accurately update the Progress object.
+            $total_rows += $tbl->{chunk_size};
+         }
 
-            # Every table should have a Progress obj; update it.
-            if ( my $tbl_pr = $tbl->{progress} ) {
-               $tbl_pr->update( sub { return $total_rows } );
+         # Update the rate of rows per second for the entire server.
+         # This is used for the initial chunk size of the next table.
+         $total_time += $tbl->{nibble_time};
+         $avg_rate    = int($total_rows / $total_time);
+         PTDEBUG && _d('Average copy rate (rows/s):', $avg_rate);
+
+         # Every table should have a Progress obj; update it.
+         if ( my $tbl_pr = $tbl->{progress} ) {
+            $tbl_pr->update( sub { return $total_rows } );
+
+            # Update the jobsize on the Progress obj every N seconds (where N is set
+            # by the --update-tablesize-interval command-line argument). Doing this
+            # makes the copy % number much more accurate for long-running oscs,
+            # since the size of the table being migrated is likely to change while
+            # the osc is running.
+            if ( ($total_time - $last_prog_upd_time) > $update_tablesize_interval ) {
+               my ($n_rows) = NibbleIterator::get_row_estimate(
+                  Cxn   => $cxn,
+                  tbl   => $tbl,
+               );
+               $tbl_pr->set_jobsize($n_rows);
+               $last_prog_upd_time = $total_time;
+            }
+         }
+
+         # Save the primary key value of the last successfully copied row into a file.
+         # If last_upper is set, that means that all rows have been copied and
+         # we should save last_upper to the state file
+         if ( $nibble_iter->{current_state} ) {
+            my $tbl_progress = $total_rows;
+            if ( $loaded_tbl_progress ) {
+               $tbl_progress = $tbl_progress + $loaded_tbl_progress;
+            }
+            if ( $nibble_iter->boundaries()->{last_upper} ) {
+               $nibble_iter->{current_state}->save(
+                  step         => 'copy',
+                  mig_tbl      => $new_tbl->{tbl},
+                  tbl_progress => $tbl_progress,
+                  row          => $nibble_iter->boundaries()->{last_upper}
+               );
+            }
+            else {
+               $nibble_iter->{current_state}->save(
+                  step         => 'copy',
+                  mig_tbl      => $new_tbl->{tbl},
+                  tbl_progress => $tbl_progress,
+                  row          => $nibble_iter->boundaries()->{next_lower}
+               );
             }
          }
 
@@ -9746,6 +9989,9 @@ sub main {
       tbl                => $orig_tbl,
       chunk_size         => $orig_tbl->{chunk_size},
       chunk_index        => $o->get('chunk-index'),
+      current_state      => $current_state,
+      loaded_step        => $loaded_step,
+      loaded_row         => $loaded_row,
       n_chunk_index_cols => $o->get('chunk-index-columns'),
       dml                => $dml,
       select             => $select,
@@ -9771,8 +10017,15 @@ sub main {
         && !$nibble_iter->one_nibble()
         &&  $nibble_iter->row_estimate() )
    {
+      my $jobsize;
+      if ( $loaded_tbl_progress ) {
+         $jobsize = $nibble_iter->row_estimate() - $loaded_tbl_progress;
+      }
+      else {
+         $jobsize = $nibble_iter->row_estimate(),
+      }
       $orig_tbl->{progress} = new Progress(
-         jobsize => $nibble_iter->row_estimate(),
+         jobsize => $jobsize,
          spec    => $o->get('progress'),
          name    => "Copying $orig_tbl->{name}",
       );
@@ -9786,7 +10039,9 @@ sub main {
    # Start copying rows.  This may take awhile, but --progress is on
    # by default so there will be progress updates to stderr.
    eval {
-      1 while $nibble_iter->next();
+      # Pass options to the nibble iterator so we can access them down
+      # the line.
+      1 while $nibble_iter->next($o);
    };
    if ( $EVAL_ERROR ) {
       die ts("Error copying rows from $orig_tbl->{name} to "
@@ -9835,6 +10090,42 @@ sub main {
       $plugin->after_copy_rows();
    }
 
+   if ( $o->get('log-timings') ) {
+      my $copy_end = time;
+      my $copy_seconds = $copy_end - $copy_start;
+
+      my ($orig_data_length, $orig_index_length, $orig_table_rows) = get_table_stats(
+         tbl    => $orig_tbl,
+         Cxn    => $cxn,
+         Quoter => $q,
+      );
+      # If we don't sleep, information_schema won't have the correct numbers for
+      # the new table at the time this query is run.
+      use Time::HiRes;
+      Time::HiRes::sleep(10);
+      my ($new_data_length, $new_index_length, $new_table_rows) = get_table_stats(
+         tbl    => $new_tbl,
+         Cxn    => $cxn,
+         Quoter => $q,
+      );
+      my $orig_table_size = $orig_data_length + $orig_index_length;
+      my $new_table_size = $new_data_length + $new_index_length;
+
+      use Sys::Syslog qw( :DEFAULT setlogsock);
+      setlogsock('unix');
+      openlog($0,'','user');
+      my $log_string = "online-schema-change copy completed. original table size: $orig_table_size, "
+         . "new table size: $new_table_size, original table rows: $orig_table_rows, "
+         . "new table rows: $new_table_rows, seconds from start of copy: $copy_seconds";
+      syslog('err', $log_string);
+      closelog;
+      print ts("$log_string...\n");
+   }
+
+   if ( defined $o->get('exit-at') && $o->get('exit-at') eq 'copy' ) {
+      return 0;
+   }
+
    # #####################################################################
    # XXX
    # Step 5: Rename tables: orig -> old, new -> orig
@@ -9988,14 +10279,27 @@ sub main {
       }
    }
 
+   if ( $current_state) {
+      $current_state->save(
+         step    => 'rename',
+         mig_tbl => $new_tbl->{tbl},
+         old_tbl => $old_tbl->{tbl}
+      );
+   }
+   if ( defined $o->get('exit-at') && $o->get('exit-at') eq 'rename' ) {
+      return 0;
+   }
+
    # ########################################################################
    # Step 7: Drop the old table.
    # ########################################################################
+   SAVED_RENAME:
    if ( $o->get('drop-old-table') ) {
       if ( $o->get('dry-run') ) {
          print "Not dropping old table because this is a dry run.\n";
       }
-      elsif ( !$old_tbl ) {
+      elsif ( !$old_tbl &&
+         (!defined $loaded_step || (defined $loaded_step && $loaded_step ne 'rename'))) {
          print "Not dropping old table because --no-swap-tables was specified.\n";
       }
       else {
@@ -10016,7 +10320,13 @@ sub main {
             $cxn->dbh()->do($sql);
          }
 
-         my $sql = "DROP TABLE IF EXISTS $old_tbl->{name}";
+         my $sql;
+         if (defined $loaded_step && $loaded_step eq 'rename') {
+            $sql = "DROP TABLE IF EXISTS $loaded_old_tbl";
+         }
+         else {
+            $sql = "DROP TABLE IF EXISTS $old_tbl->{name}";
+         }
          print $sql, "\n" if $o->get('print');
          PTDEBUG && _d($sql); 
          eval {
@@ -10025,7 +10335,12 @@ sub main {
          if ( $EVAL_ERROR ) {
             die ts("Error dropping the old table: $EVAL_ERROR\n");
          }
-         print ts("Dropped old table $old_tbl->{name} OK.\n");
+         if (defined $loaded_step && $loaded_step eq 'rename') {
+            print ts("Dropped old table $loaded_old_tbl OK.\n");
+         }
+         else {
+            print ts("Dropped old table $old_tbl->{name} OK.\n");
+         }
 
          # --plugin hook
          if ( $plugin && $plugin->can('after_drop_old_table') ) {
@@ -10410,6 +10725,7 @@ sub create_new_table {
    }
    my ($new_table_name, $orig_tbl, $cxn, $q, $o, $tp) = @args{@required_args};
    my $new_table_prefix = $args{new_table_prefix};
+   my $loaded_step = $args{loaded_step};
 
    # Get the original table struct.
    my $ddl = $tp->get_create_table(
@@ -10424,6 +10740,17 @@ sub create_new_table {
    my $tries = $new_table_prefix ? 10 : 1;
    my $tryno = 1;
    my @old_tables;
+
+   # If running from a previously saved state, don't create a temp table (it
+   # has already been created).
+   if ( defined $loaded_step && grep { $_ eq $loaded_step } qw(create triggers copy rename)) {
+      $new_table_name = $new_table_prefix . $new_table_name;
+      return { # success
+         db   => $orig_tbl->{db},
+         tbl  => $new_table_name,
+         name => $q->quote($orig_tbl->{db}, $new_table_name),
+      };
+   }
    while ( $tryno++ <= $tries ) {
       if ( $new_table_prefix ) {
          $new_table_name = $new_table_prefix . $new_table_name;
@@ -10583,6 +10910,15 @@ sub swap_tables {
       }
 
       print ts("Swapping tables...\n");
+      if ( $o->get('swap-table-name') ) {
+         $table_name = $o->get('swap-table-name');
+         $table_name =~  s/%T/$orig_tbl->{name}/g;
+         use POSIX 'strftime';
+         my $timestamp = strftime("%Y%m%d%H%M%S", localtime(time()));
+         $table_name =~  s/%D/$timestamp/g;
+      } else {
+         $table_name = $prefix . $table_name;
+      }
       while ( $name_tries-- ) {
        
          # https://bugs.launchpad.net/percona-toolkit/+bug/1526105
@@ -10632,6 +10968,7 @@ sub swap_tables {
          if ( my $e = $EVAL_ERROR ) {
             if ( $e =~ $table_exists ) {
                PTDEBUG && _d($e);
+               $table_name = $prefix . $table_name;
                next;
             }
             die ts($e);
@@ -10653,6 +10990,28 @@ sub swap_tables {
    }
 }
 
+sub get_table_stats {
+   my ( %args ) = @_;
+   my @required_args = qw(tbl Cxn Quoter);
+   foreach my $arg ( @required_args ) {
+      die "I need a $arg argument" unless $args{$arg};
+   }
+   my ($tbl, $cxn, $q) = @args{@required_args};
+
+   PTDEBUG && _d('Getting table stats');
+   my $sql = "SELECT DATA_LENGTH, INDEX_LENGTH, TABLE_ROWS "
+           . "FROM information_schema.tables "
+           . "WHERE table_schema='$tbl->{db}' "
+           . "AND table_name='$tbl->{tbl}'";
+   PTDEBUG && _d($sql);
+   my $row = $cxn->dbh()->selectrow_hashref($sql);
+   PTDEBUG && _d(Dumper($row));
+   my $data_length = $row->{data_length} || 0;
+   my $index_length = $row->{index_length} || 0;
+   my $table_rows = $row->{table_rows} || 0;
+   return $data_length, $index_length, $table_rows;
+}
+
 sub check_orig_table {
    my ( %args ) = @_;
    my @required_args = qw(orig_tbl Cxn TableParser OptionParser Quoter);
@@ -10660,6 +11019,7 @@ sub check_orig_table {
       die "I need a $arg argument" unless $args{$arg};
    }
    my ($orig_tbl, $cxn, $tp, $o, $q) = @args{@required_args};
+   my $loaded_step = $args{loaded_step};
 
    my $dbh = $cxn->dbh();
 
@@ -10674,7 +11034,10 @@ sub check_orig_table {
            . ' LIKE ' . $q->literal_like($orig_tbl->{tbl});
    PTDEBUG && _d($sql);
    my $triggers = $dbh->selectall_arrayref($sql);
-   if ( $triggers && @$triggers ) {
+   # Don't quit on existing triggers if running from a saved state. The triggers
+   # are expected to be present.
+   if ( $triggers && @$triggers &&
+         (!defined $loaded_step || (defined $loaded_step && !grep { $_ eq $loaded_step } qw(triggers copy rename)))) {
        if ( VersionCompare::cmp($version, '5.7.0') < 0  && VersionCompare::cmp($version, '10.0.0') <= 0) {
            die "The table $orig_tbl->{name} has triggers.  This tool "
              . "needs to create its own triggers, so the table cannot "
@@ -11003,6 +11366,7 @@ sub create_triggers {
       die "I need a $arg argument" unless $args{$arg};
    }
    my ($orig_tbl, $new_tbl, $del_tbl, $cols, $cxn, $q, $o, $retry, $tries, $stats) = @args{@required_args};
+   my $loaded_step = $args{loaded_step};
 
    # This sub works for --dry-run and --execute.  With --dry-run it's
    # only interesting if --print is specified, too; then the user can
@@ -11162,7 +11526,9 @@ sub create_triggers {
 
    foreach my $trigger_info ( @$triggers_info ) {
        next if !$trigger_info->{new_trigger_sql};
-       if ( $o->get('execute') ) {
+       # Don't create triggers if running from a saved state. They should already
+       # be there.
+       if ( $o->get('execute') && (!defined $loaded_step || (defined $loaded_step && !grep { $_ eq $loaded_step } qw(triggers copy rename))) ) {
           osc_retry(
              Cxn     => $cxn,
              Retry   => $retry,
@@ -11431,11 +11797,12 @@ sub exec_nibble {
    );
 
    return osc_retry(
-      Cxn     => $cxn,
-      Retry   => $retry,
-      tries   => $tries->{copy_rows},
-      stats   => $stats,
-      code    => sub {
+      Cxn         => $cxn,
+      Retry       => $retry,
+      tries       => $tries->{copy_rows},
+      stats       => $stats,
+      nibble_iter => $nibble_iter,
+      code        => sub {
          # ###################################################################
          # Start timing the query.
          # ###################################################################
@@ -12206,7 +12573,7 @@ Drop the new table if copying the original table fails.
 
 Specifying C<--no-drop-new-table> and C<--no-swap-tables> leaves the new,
 altered copy of the table without modifying the original table.  See
-L<"--new-table-name">.
+L<"--new-table-name"> and L<"--swap-table-name">.
 
 L<--no-drop-new-table> does not work with
 C<alter-foreign-keys-method drop_swap>.
@@ -12307,6 +12674,16 @@ for every row.
 To make this scenario vissible to the user, if there are indexes having ENUM fields 
 with usorted items, it is necessary to specify the C<--force-concat-enums> parameter.
 
+=item --exit-at
+
+type: string
+
+If defined, arg must specify one of the follow points to exit:
+* create (after creating and altering the new table)
+* triggers (after creating the triggers)
+* copy (after copying the data to the new table)
+* rename (after renaming the tables)
+
 =item --help
 
 Show help and exit.
@@ -12329,6 +12706,19 @@ detected.
 Default is no Flow Control checking.
 This option is available for PXC versions 5.6 or higher.
 
+=item --load-state
+
+type: string
+
+Load the state of an incomplete online schema change from a file, and continue the
+schema change from where it previously stopped.  See also L<"--save-state">.
+
+=item --log-timings
+
+Log original table_size (data_length + index_length), new table_size, original
+table_rows, new table_rows, and the number of seconds the copy step took, to
+STDERR and syslog after the copy is completed.
+
 =item --max-lag
 
 type: time; default: 1s
@@ -12438,7 +12828,7 @@ New table name before it is swapped.  C<%T> is replaced with the original
 table name.  When the default is used, the tool prefixes the name with up
 to 10 C<_> (underscore) to find a unique table name.  If a table name is
 specified, the tool does not prefix it with C<_>, so the table must not
-exist.
+exist.  See also L<"--swap-table-name">.
 
 =item --null-to-not-null
 
@@ -12590,6 +12980,14 @@ Sets the password to be used to connect to the slaves.
 It can be used with --slave-user and the password for the user must be the same
 on all slaves.
 
+=item --save-state
+
+type: string
+
+Continuously save the state of the online schema change to a file as it runs.
+This file can then be used to continue a schema change that has been stopped for some
+reason.  See also L<"--load-state">.
+
 =item --set-vars
 
 type: Array
@@ -12653,6 +13051,18 @@ Using C<--no-swap-tables> will run the whole process, it will create the new
 table, it will copy all rows but at the end it will drop the new table. It is 
 intended to run a more realistic L<--dry-run>.
 
+=item --swap-table-name
+
+type: string
+
+Name for the old table after it is swapped.  There are 2 symbols that can  be
+used in the name - C<%T>, which is replaced with the original table name, and
+C<%D>, which is replaced with the timestamp (evaluated at rename time) in
+'YYYYmmddHHMMSS' format.  If a table already exists with that name, up to 9
+underscores are prefixed and any characters after the 64th are truncated.  If
+this option is not specified, the standard rename method is used.  See also
+L<"--new-table-name">.
+
 =item --tries
 
 type: array
@@ -12713,6 +13123,15 @@ reconnect.
 
 Failures and retries are recorded in the L<"--statistics">.
 
+=item --update-tablesize-interval
+
+type: time; default: 500
+
+How often the size of the original table should be recalculated, in seconds.
+The size of the table is used to calculate the progress of an osc, so
+updating this number at regular intervals will make the progress reporting
+of long-running oscs more accurate.
+
 =item --user
 
 short form: -u; type: string
